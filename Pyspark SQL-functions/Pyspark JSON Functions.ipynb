{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "628f2253-c989-48eb-bf47-3dc0396f541f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Setting Environment Varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bbf32a0-0fed-4730-a21c-c457111536ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34eb01e5-d35a-4f3c-b5a3-c8ec1d60765a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dac7a29-74cc-410d-b8b3-fc026f5e2f9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"JSON Functions\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a6e1633-36b1-45c8-8ca4-7a6d96ba3cd4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "json_string = \"\"\"{\"ZipCode\" : 704, \"ZipCodeType\" : \"Standard\", \"City\" : \"PARC PARQUE\", \"Country\" : \"PR\"}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84d11ad6-00bb-4784-968c-6b11dff9af48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------------------------------------------------------------+\n|id |value                                                                                  |\n+---+---------------------------------------------------------------------------------------+\n|1  |{\"ZipCode\" : 704, \"ZipCodeType\" : \"Standard\", \"City\" : \"PARC PARQUE\", \"Country\" : \"PR\"}|\n+---+---------------------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([(1, json_string)], [\"id\", \"value\"])\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afb59cdd-6a3c-42e7-99c9-4e73a6d4c57e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Json Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18389440-3cc6-428d-8eb8-f0ab48b90282",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 1.from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fc40fca-2ade-4708-936a-669a4596f835",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###### Map Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c2ef741-abd1-452a-945a-371f50096aa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------------------------------------+\n|id |value                                                                        |\n+---+-----------------------------------------------------------------------------+\n|1  |{ZipCode -> 704, ZipCodeType -> Standard, City -> PARC PARQUE, Country -> PR}|\n+---+-----------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import MapType, StringType\n",
    "from pyspark.sql.functions import from_json\n",
    "df2 = df.withColumn(\"value\", from_json(df.value, MapType(StringType(), StringType())))\n",
    "df2.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c609172-389e-40f0-9197-681bd37f371f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###### StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45ae55ca-69cf-486f-b901-8fbe018e9b76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- value: struct (nullable = true)\n |    |-- ZipCode: string (nullable = true)\n |    |-- ZipCodeType: string (nullable = true)\n |    |-- City: string (nullable = true)\n |    |-- Country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField,StructType,StringType\n",
    "# Creating Schema for JSON\n",
    "schema = StructType([\n",
    "    StructField(\"ZipCode\", StringType(), True),\n",
    "    StructField(\"ZipCodeType\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Country\", StringType(), True)\n",
    "])\n",
    "# Converting JSON Strig to Struct Type\n",
    "df3=df.withColumn(\"value\",from_json(df.value,schema))\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6681fc31-2d92-437c-bf0b-7fad3102590f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------+\n|id |value                           |\n+---+--------------------------------+\n|1  |{704, Standard, PARC PARQUE, PR}|\n+---+--------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f625fee-f897-43f7-9360-38f1f34ca664",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+-----------+-------+\n| id|ZipCode|ZipCodeType|       City|Country|\n+---+-------+-----------+-----------+-------+\n|  1|    704|   Standard|PARC PARQUE|     PR|\n+---+-------+-----------+-----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "df4=df3.select(\"id\",\"value.*\")\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c43376a-4af4-4510-9c5e-fdb0634a0691",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 2.to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f5f9696-dae7-4107-b356-13c0f84c205b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------------------------+\n|id |value                                                                         |\n+---+------------------------------------------------------------------------------+\n|1  |{\"ZipCode\":\"704\",\"ZipCodeType\":\"Standard\",\"City\":\"PARC PARQUE\",\"Country\":\"PR\"}|\n+---+------------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json,col\n",
    "df2.withColumn(\"value\",to_json(col(\"value\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11fa733f-ad26-4d03-8469-27b191bbc253",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 3.json_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f4ba403-4e6b-43ef-a88c-c42fb2c5b695",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------+\n| Id|Zip| ZipType|\n+---+---+--------+\n|  1|704|Standard|\n+---+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import json_tuple\n",
    "df.select(col(\"id\"),json_tuple(col(\"value\"),\"ZipCode\",\"ZipCodeType\"))\\\n",
    "    .toDF(\"Id\",\"Zip\",\"ZipType\")\\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8247461b-7fd2-4418-b56b-b691286e719e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 4.get_json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ef5f71e-186f-47ab-ac27-28731b153731",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+\n| id|Code|Country|\n+---+----+-------+\n|  1| 704|     PR|\n+---+----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import get_json_object\n",
    "df.select(col(\"id\"),get_json_object(col(\"value\"),\"$.ZipCode\").alias(\"Code\"),get_json_object(col(\"value\"),\"$.Country\").alias(\"Country\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93fd6cdf-cf6e-4a56-b2d0-f1109d8bf813",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 5.schema_of_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa6ca4da-0c9f-4fc9-b546-4fd565fb4e7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRUCT<City: STRING, Country: STRING, ZipCode: BIGINT, ZipCodeType: STRING>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import schema_of_json, lit\n",
    "schemaStr = spark.range(1) \\\n",
    "    .select(schema_of_json(lit(json_string))) \\\n",
    "    .collect()[0][0]\n",
    "print(schemaStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1d164dd-ebc4-4ab8-a2bb-67557c8be2f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark JSON Functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
